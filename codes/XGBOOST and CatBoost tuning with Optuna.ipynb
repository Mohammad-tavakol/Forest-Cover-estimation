{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "#import datasets\n",
    "data= read_csv(r\"~/forest_balanced.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb070ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:11]\n",
    "Y=data.iloc[:,11]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7706708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import catboost as cb\n",
    "from sklearn.metrics import accuracy_score\n",
    "def objective(trial):\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "    param = {\n",
    "        \"model_size_reg\":trial.suggest_float(\"model_size_reg\",2, 6),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\",2, 7),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\", 0.01, 0.5),\n",
    "        \"loss_function\": \"MultiClass\",\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),}\n",
    "\n",
    "    \n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    CB = cb.CatBoostClassifier(**param)\n",
    "\n",
    "    CB.fit(train_x, train_y, eval_set=[(valid_x, valid_y)], verbose=0)\n",
    "\n",
    "    preds = CB.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=300)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ac3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "CB=CatBoostClassifier(iterations=2500,\n",
    "                        learning_rate=0.1, depth=7, l2_leaf_reg=3,\n",
    "                        model_size_reg=2, loss_function='MultiClassOneVsAll',verbose=250,eval_metric='Accuracy',task_type='GPU');\n",
    "\n",
    "cb = CB.fit(xtrain, ytrain,eval_set=(xtest,ytest))\n",
    "cb_trscore=cb.score(xtrain,ytrain)\n",
    "ypred_cb=cb.predict(xtest)\n",
    "print(\"cb Train Accuracy:\",cb_trscore)\n",
    "print(\"cb Test Accuracy:\", metrics.accuracy_score(ytest, ypred_cb))\n",
    "print('----------------------------------------')\n",
    "print('* cb Classification Report')\n",
    "print(classification_report(ytest, ypred_cb))\n",
    "print('----------------------------------------')\n",
    "print('* cb Confusion Matrix')\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(ytest, ypred_cb)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cmn, annot=True,cmap='RdPu',  fmt='.2f',xticklabels=[\"C1\", \"C2\", \"C3\", \"C4\",\"C5\",\"C6\",\"C7\"],\n",
    "            yticklabels=[\"C1\", \"C2\", \"C3\", \"C4\",\"C5\",\"C6\",\"C7\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0ba0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost optimization\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(X, Y, test_size=0.3)\n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\"num_class\":7,\n",
    "        \"verbosity\": 0,\n",
    "#        \"objective\":trial.suggest_categorical(\"objective\",[ \"multi:softmax\",\"multi:softprob\"]),\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\":trial.suggest_categorical(\"tree_method\", [\"exact\" ,\"approx\"]),\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "         \"max_depth\": trial.suggest_int(\"max_depth\", 1, 120),\n",
    "             \"n_estimators\":trial.suggest_int(\"n_estimators\", 1, 2000)\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        # defines how selective algorithm is.\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=240, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "XGB=xgboost.XGBClassifier(objective=\"multi:softprob\", max_depth=9, n_estimators=250,booster='gbtree',min_child_weight=0.9,subsample=0.5)\n",
    "\n",
    "xgb = XGB.fit(xtrain, ytrain)\n",
    "xgb_trscore=xgb.score(xtrain,ytrain)\n",
    "ypred_xgb=xgb.predict(xtest)\n",
    "print(\"xgb Train Accuracy:\",xgb_trscore)\n",
    "print(\"xgb Test Accuracy:\", metrics.accuracy_score(ytest, ypred_xgb))\n",
    "print('----------------------------------------')\n",
    "print('* xgb Classification Report')\n",
    "print(classification_report(ytest, ypred_xgb))\n",
    "print('----------------------------------------')\n",
    "print('* xgb Confusion Matrix')\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(ytest, ypred_xgb)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cmn, annot=True,cmap='RdPu',  fmt='.2f',xticklabels=[\"C1\", \"C2\", \"C3\", \"C4\",\"C5\",\"C6\",\"C7\"],\n",
    "            yticklabels=[\"C1\", \"C2\", \"C3\", \"C4\",\"C5\",\"C6\",\"C7\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc52c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
